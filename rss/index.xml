<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Untitled RSS Feed]]></title><description><![CDATA[Untitled RSS Feed]]></description><link>https://elinep.github.io/blog</link><generator>RSS for Node</generator><lastBuildDate>Mon, 12 Jun 2017 15:32:45 GMT</lastBuildDate><atom:link href="https://elinep.github.io/blog/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Neural Networks Training : basic concepts]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>I rencently started to interest in neural networks appealled by all the magic articles/results that flowd the web.
When you see magic, you want to understand the trick. That’s my case.
A great ressource to study this subject is the
<a href="https://www.youtube.com/watch?v=yp9rwI_LZX8&amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg">Convolutional Neural Networks</a> course by standford.
This series of video are nice and show that neural networks concept are affordable.
Still there are few points that struggle me for a while and my modest intent is
that this post freshly written after having watched the video can help.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_what_is_a_neural_network">What is a neural network ?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>OK first, what kind of beast a neural network is and what’s its purpose. Well it’s just a giant function that process some input based on some parameters to compute some output.</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="https://elinep.github.io/blog/images/2017-06-12-neural_networks_training_basics/fig1.png" alt="fig1.png">
</div>
<div class="title">Figure 1. Abstract view of a neural network</div>
</div>
<div class="paragraph">
<p>So basically you present to your network some input data (images, numbers, text) and it generates an ouput (images, numbers, text) by computing
\(Y = f(X,W)\)</p>
</div>
<div class="paragraph">
<p>Note that the dimensions of \(X\),\(Y\) and \(W\) are generally different. For example for an image classification task:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>\(X\) will be the dimensions of the image (example 128x128)</p>
</li>
<li>
<p>\(Y\) will be the number of class (example 10) you want to detect</p>
</li>
<li>
<p>\(W\) can be very large like millions of coefficients</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The \(f()\) function is a kind of generic one defined by your network architecture and depends on:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>type of neuron</p>
</li>
<li>
<p>number of neurons</p>
</li>
<li>
<p>how neurons interconnect each other</p>
</li>
<li>
<p>&#8230;&#8203;</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Its behaviour is driven by the weights. The weights are the parameters you have to tune so that \(f()\) does something interesting i.e. produces releavant ouput given the input and not just garbage.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_what_is_training">What is training ?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The goal of training is to find the value of the weights so that the network generates correct output.</p>
</div>
<div class="paragraph">
<p>On supervised learning you present examples of input data and expected output. At the beginning the network will generate ouputs far different from the expected ones.</p>
</div>
<div class="paragraph">
<p>The difference between ouput and expected output is used to update the weights so that the error decreased.</p>
</div>
<div class="paragraph">
<p>After many example submission and weights optimisation cycle, you hope your network works correctly and can predict correctly new ouput with unseen data.</p>
</div>
<div class="paragraph">
<p>So basically network training is a function fitting task.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_how_do_you_train">How do you train ?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Ok first we need to measure the error between an expected output and current ouput of the network.</p>
</div>
<div class="paragraph">
<p>This is called a loss function and it is added at the end of the network like this:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="https://elinep.github.io/blog/images/2017-06-12-neural_networks_training_basics/fig2.png" alt="fig2.png">
</div>
<div class="title">Figure 2. Loss function to compute error</div>
</div>
<div class="paragraph">
<p>The loss function should have several properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>its input are the ouput of the network and the ouput from the training data</p>
</li>
<li>
<p>its ouput is a scalar</p>
</li>
<li>
<p>it should measure properly the error : the more \(Y\) and \(\tilde{Y}\) are close, the less the error must be</p>
</li>
<li>
<p>it must be differentiable</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>There are several ad-hoc loss function that we can use depending on our application.
A very simple one - the \(L2\) norm - consists in summing the square error on each ouput dimensions:</p>
</div>
<div class="paragraph">
<p>\(L(Y,\tilde{Y}) = \sum{(Y_i-\tilde{Y_i})^2}\)</p>
</div>
<div class="paragraph">
<p>The training consists of finding the weights of the network that minimize the error. In math language, we perform
\(\underset{W}{\arg\min{}} L(Y,\tilde{Y})\)</p>
</div>
<div class="paragraph">
<p>It’s not a straight forward job. The problem is that the loss function is on top of the network which is a giant non linear function. We can’t compute the minimum right away from the data, network and loss function.</p>
</div>
<div class="paragraph">
<p>Ok, how do we do then ? The answer is Gradient descent.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_gradient_descent">Gradient descent</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Gradient descent is widely use to optimize function parameter. The basic idea is to test how the error evolves when slightly modifying each parameter.</p>
</div>
<div class="sect2">
<h3 id="_analogy">Analogy</h3>
<div class="paragraph">
<p>The famous analogy is a blind folded walker in the mountain looking for the valley.</p>
</div>
<div class="paragraph">
<p>One possible strategy is to sense the slope by making tiny steps:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>make a tiny step forward (X-axis) and sense if you’re going uphill or downhill (i.e. watch how you move on Z-axis). Go back to your position</p>
</li>
<li>
<p>make a tiny side step (Y-axis) and sense if you’re going uphill or downhill (i.e. watch how you move on Z-axis). Go back to your position</p>
</li>
<li>
<p>Thanks to this two steps, you know how the slope is oriented and you can make a step in the correct dirrection, generally a mixed of X and Y</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>After severall iterrations you likely end in the valley, or at least in a local valley.</p>
</div>
<div class="paragraph">
<p>The analogy points are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>the altitude (along Z-axis) is the error</p>
</li>
<li>
<p>your position (along X-axis and Y-axis) are the 2 parameters you want to optimize to find the minimum error</p>
</li>
<li>
<p>the tiny steps to sense the slope is the gradient</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_simple_example">Simple example</h3>
<div class="paragraph">
<p>Let’s formalize a bit this strategy with an example.
Imagine you have the following loss function:</p>
</div>
<div class="paragraph">
<p>\(L(w_1,w_2) = (w_1+2)^2+4(w_2-1)^2+3\)</p>
</div>
<div class="paragraph">
<p>To perform gradient descent, we need to compute the gradient of this loss function.
The gradient is just the set of partial derative of the loss function for the weight parameters.</p>
</div>
<div class="paragraph">
<p>\(
\nabla L(w_1,w_2) =
\begin{bmatrix}
\frac{\partial L(w_1,w_2)}{\partial w_1}
\\
\frac{\partial L(w_1,w_2)}{\partial w_2}
\end{bmatrix}\)</p>
</div>
<div class="paragraph">
<p>The partial derivatives allows us to evaluate the slope along each axis at any given position.</p>
</div>
<div class="paragraph">
<p>Our simple loss function is easy to derivate:</p>
</div>
<div class="paragraph">
<p>\(
\nabla L(w_1,w_2) =
\begin{bmatrix}
\frac{\partial L(w_1,w_2)}{\partial w_1}
\\
\frac{\partial L(w_1,w_2)}{\partial w_2}
\end{bmatrix}
=
\begin{bmatrix}
2w_1+2
\\
8w_2-8
\end{bmatrix}\)</p>
</div>
<div class="paragraph">
<p>Now that we can compute the slope we can run the algorithm :</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>evaluate the local gradient at the current position</p>
</li>
<li>
<p>update the position by making step proportional to the local gradient</p>
</li>
<li>
<p>go back to 1.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Let’s do the first iteration:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>we start at a random position \(w_1=-5, w_2=5\)</p>
</li>
<li>
<p>we evaluate the gradient at this position
\(
\nabla L(-5,5) =
\begin{bmatrix}
\frac{\partial L(-5,5)}{\partial -5}
\\
\frac{\partial L(-5,5)}{\partial 5}
\end{bmatrix}
=
\begin{bmatrix}
2\times-5+2
\\
8\times5-8
\end{bmatrix}
=
\begin{bmatrix}
-8
\\
32
\end{bmatrix}\)
which means that locally the error decreases a bit when \(w_1\) increases,
and the error increases a lot when \(w_2\) increases.
Therefore to go downhill we have to increase \(w_1\) and decrease \(w_2\)</p>
</li>
<li>
<p>Update current position to go downhill
\(
\begin{bmatrix}
w_1
\\
w_2
\end{bmatrix}
=
\begin{bmatrix}
w_1
\\
w_2
\end{bmatrix}
-
\lambda
\nabla L(w_1,w_2)
=
\begin{bmatrix}
-5+8\lambda
\\
5-32\lambda
\end{bmatrix}\)
where \(\lambda\) is a scalar parameter to control the size of your step</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Here is graphically what happens for few iterrations with \(\lambda=0.04\)</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="https://elinep.github.io/blog/images/2017-06-12-neural_networks_training_basics/fig_gradient_descent.png" alt="fig gradient descent.png">
</div>
<div class="title">Figure 3. Gradient descent iterations for a simple function - The red dot, is the initial position. The arrows represents the evaluation of the current gradient (the slope on each axis). The green path links the postion that have been tested by the algorithm. The surface is the loss function.</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
When to stop the algorithm? Generally for neural networks training, you run it a fix number of times. It is one of your hyperparameter. In the same time you monitor that your error behave correctly (i.e. decreases)
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Here we presented the basic gradient descent algorithm.
It has a disavantage of being very slow (you need a lot of iterration to find the best position).
There are clever way to update the position but they all rely on the local gradient evaluation.</p>
</div>
<div class="paragraph">
<p>Ok so to train a neural network, we need to compute the partial derivative of the loss:</p>
</div>
<div class="paragraph">
<p>\(\frac{\partial L(f(X,W),\tilde{Y})}{\partial{W_i}}\)</p>
</div>
<div class="paragraph">
<p>The problem is that it’s not straightforward as \(f()\) can be very complex.
We can’t compute it by hand as we did with our little example.We could evaluate
numerically the gradient by running the network with tiny variation on each weight
at a time and monitor the error but it has drawbacks:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>it is an approximation</p>
</li>
<li>
<p>you need to run the network (i.e. evaluate ) as many times as the number of weights just for one gradient descent iterration which is impratical.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The solution is the backward propagation.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_backward_propagation">Backward propagation</h2>
<div class="sectionbody">
<div class="paragraph">
<p>So far we abstracted the neural network with the function \(Y = f(X,W)\).
Before introducing back propagation, let’s see how this function looks like.</p>
</div>
<div class="sect2">
<h3 id="_neural_networks_under_the_hood">Neural networks, under the hood</h3>
<div class="paragraph">
<p>A neural network is a composition of elementary functions called neurons.
The neuron transformation is quite basic. It combines the input and generate a scalar output.
There are several variants but here is a typical one:</p>
</div>
<div class="paragraph">
<p>\(Y = f_{neuron}(X,W,B) = \max(0,\sum\limits_{i=0}^{N}{(X_i \cdot W_i)}+B)\)</p>
</div>
<div class="paragraph">
<p>with \(Y \in \mathbb{R}\), \(X \in \mathbb{R}^N\), \(W \in \mathbb{R}^{N}\)
and \(B \in \mathbb{R}\)</p>
</div>
<div class="paragraph">
<p>This function simply computes a weighted sum of the input data,
add a bias and saturates the result with \(\max()\). The \(\max()\) part is called the activation function.
There are different possible activation functions.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The bias like the weights is a parameter that needs to be trained.
That’s why \(B\) is often omitted and included in \(W\) and we simply write: \(Y = f_{neuron}(X,W)\)
with \(W \in \mathbb{R}^{N+1}\)
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>By chaining several layers of neurons, you obtain a neural network:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="https://elinep.github.io/blog/images/2017-06-12-neural_networks_training_basics/fig3.png" alt="fig3.png">
</div>
<div class="title">Figure 4. A neural network</div>
</div>
<div class="paragraph">
<p>Backward propagation is a recursive method to evaluate the gradient of
the loss function (i.e. \(\frac{\partial L(Y,\tilde{Y})}{\partial W_i}\))
by considering one simple neuron at a time.</p>
</div>
</div>
<div class="sect2">
<h3 id="_chain_rule">Chain rule</h3>
<div class="paragraph">
<p>Backward propagation relies on the chain rule.
The chain rule is a method to compute the derivative of the composition of two functions.</p>
</div>
<div class="paragraph">
<p>Consider two functions \(y_f=f(x_f)\), \(y_g=g(x_g)\) and compose them to form a third one \(y=h(x)=g(f(x))\)</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="https://elinep.github.io/blog/images/2017-06-12-neural_networks_training_basics/fig4.png" alt="fig4.png">
</div>
<div class="title">Figure 5. Composition of two functions</div>
</div>
<div class="paragraph">
<p>Chain rule states:</p>
</div>
<div class="paragraph">
<p>\(\frac{df}{dx}(a) = \frac{dg}{df}(f(a)) \cdot \frac{df}{dx}(a)\)</p>
</div>
<div class="paragraph">
<p>In other word, to derivate a composition of function we simply multiply the derivative of the
underlying functions where they are evaluated.</p>
</div>
<div class="paragraph">
<p>Let’s see with an example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>\(f(x)=3x+1\)</p>
</li>
<li>
<p>\(g(f)=f^2\)</p>
</li>
<li>
<p>\(h(x)=g(f(x))=(3x+1)^2=9x^2+6x+1\)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>By evaluating the derivative of \(h\) on point \(a\) directly we find :</p>
</div>
<div class="paragraph">
<p>\(\frac{dh}{dx}(a) = 18a+6\)</p>
</div>
<div class="paragraph">
<p>With the chain rule method we find:</p>
</div>
<div class="paragraph">
<p>\(\frac{dg}{df}=2f\), \(\frac{df}{dx}=3\)</p>
</div>
<div class="paragraph">
<p>so,</p>
</div>
<div class="paragraph">
<p>\(\frac{dg}{df}(f(a))=2f(a)=2(3a+1)\), \(\frac{df}{dx}(a)=3\)</p>
</div>
<div class="paragraph">
<p>putting all together,</p>
</div>
<div class="paragraph">
<p>\(\frac{dh}{dx}(a)=\frac{dg}{df}(f(a)) \cdot \frac{df}{dx}(a) = (6a+2) \cdot 3 = 18a+6\)
as expected</p>
</div>
<div class="paragraph">
<p>From \(f\) point of view, it means that to compute the derivative regarding \(x\)
for a particuliar value \(a\), we need:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>\(\frac{df}{dx}(a)\), the local derivative</p>
</li>
<li>
<p>\(\frac{dg}{df}(f(a))\) which is the evaluation of the local derivative of the next « block » i.e the \(g\) function</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_chain_rule_applied_to_a_network">Chain rule applied to a network</h3>
<div class="paragraph">
<p>The idea of back propagation is to apply chain rule on the loss function \(L(Y,\tilde{Y})\).</p>
</div>
<div class="paragraph">
<p>For each function of the network (neurons, loss) we will evaluate the gradient of
the ouput regarding the input that are influenced by the weights of the networks.</p>
</div>
<div class="paragraph">
<p>We start by evaluating the gradient of the error on the loss function.
The loss function depends on two variable:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>the network output \(Y\) which obviously depends on the weights \(W\).
The gradient \(G_Y\) must be evaluated</p>
</li>
<li>
<p>the expected output \(\tilde{Y}\) from the training data which does not depend
on the weight. There is no need to compute \(G_{\tilde{Y}}\)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For the loss function we introduce earlier we have:</p>
</div>
<div class="paragraph">
<p>\(G_{Y_i} = \frac{\partial L(Y,\tilde{Y})}{\partial Y_i}
= \frac{\partial \sum{(Y_i-\tilde{Y_i})^2} }{\partial Y_i}
= 2(Y_i - \tilde{Y}_i)\)</p>
</div>
</div>
<div class="sect2">
<h3 id="_gradient_propagation_in_a_neuron">Gradient propagation in a neuron</h3>
<div class="paragraph">
<p>Let&#8217;s see how we propagate the gradient through a neuron.</p>
</div>
<div class="paragraph">
<p>Situation reminder:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>we have forward propagated an example in the network</p>
</li>
<li>
<p>all neurons have computed output based on their input and their current weight values</p>
</li>
<li>
<p>loss function has computed an error for this example</p>
</li>
<li>
<p>we are back propagating to find out the influence of each weight on final error for the current example</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For now, we assume we receive the gradient \(G_Y\) from the next neurons (i.e. all the neurons that use our output as input).</p>
</div>
<div class="paragraph">
<p>Thanks to the chain rule we compute the following gradients:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>the weight gradient \(G_{W_i} = G_Y \cdot \frac{\partial F_{neuron}(X,W)}{\partial W_i}\)
senses the influence of the neuron&#8217;s weights on the final error. \(G_{W_i}\) will be used to update the current neuron weights</p>
</li>
<li>
<p>the input gradient \(G_{X_i} = G_Y \cdot \frac{\partial F_{neuron}(X,W)}{\partial X_i}\) senses
the influence of the current neuron input on the final error. \(G_{X_i}\) will tell to the previous neuron how it should
modify its output so that our output help to decrease the error.</p>
</li>
</ul>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="https://elinep.github.io/blog/images/2017-06-12-neural_networks_training_basics/fig5.png" alt="fig5.png">
</div>
<div class="title">Figure 6. Gradient flow inside a neuron</div>
</div>
<div class="paragraph">
<p>With the neuron definition we have seen, we obtain:</p>
</div>
<div class="paragraph">
<p>\({F_{neuron}(X,W,B) = \max(0,\sum\limits_{i=0}^{N}{(X_i \cdot W_i)}+B)} = Y\)</p>
</div>
<div class="paragraph">
<p>\(G_{W_i} = G_Y \cdot \frac{\partial F_{neuron}(X,W,B)}{\partial W_i}
=G_Y \cdot
\Big\{
\begin{matrix}
X_i &amp; Y&gt;0 \\
0 &amp; Y \leqslant 0
\end{matrix}\)</p>
</div>
<div class="paragraph">
<p>\(G_{B} = G_Y \cdot \frac{\partial F_{neuron}(X,W,B)}{\partial W_i}
=G_Y \cdot
\Big\{
\begin{matrix}
1 &amp; Y&gt;0 \\
0 &amp; Y \leqslant 0
\end{matrix}\)</p>
</div>
<div class="paragraph">
<p>\(G_{X_i} = G_Y \cdot \frac{\partial F_{neuron}(X,W,B)}{\partial W_i}
=G_Y \cdot
\Big\{
\begin{matrix}
W_i &amp; Y&gt;0 \\
0 &amp; Y \leqslant 0
\end{matrix}\)</p>
</div>
<div class="paragraph">
<p>\(G_{X_i}\) are transmitted to previous neurons while \(G_{W_i}\) and \(G_{B}\)
are used by the gradient descent algorithm to update parameters \(W\) and \(B\) for
the current neuron.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Most of the time a neuron output is linked to multiple neurons.
Therefore during back propagation a neuron receive several \(G_{Y_i}\) gradients.
The gradient used for back propagation is simply the sum of all the incomming gradients
\(G_Y = \sum{G_{Y_i}}\) (see <a href="https://en.wikipedia.org/wiki/Chain_rule#Higher_dimensions" class="bare">https://en.wikipedia.org/wiki/Chain_rule#Higher_dimensions</a>).
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_summary">Summary</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>A neuron is a quite simple function that mixes several input and weights to generates one output.</p>
</li>
<li>
<p>A neural network is a bunch of neurons connecting each other.</p>
</li>
<li>
<p>A neural network must be trained by presenting some input and expected output to tune the weights
so that it learns to generate correct output.</p>
</li>
<li>
<p>A neural network is trained by minimizing a loss function that compute the error between an output
and the expected ouput.</p>
</li>
<li>
<p>The training use the gradient descent method to adjust the weights of the network</p>
</li>
<li>
<p>The gradient descent algorthm requires to evaluate the partial derivative of the network regarding the weight.</p>
</li>
<li>
<p>Back propagation is used to compute this partial derivative by recursively evaluating the gradient from the loss function
to the first neurons of the network</p>
</li>
</ul>
</div>
</div>
</div>]]></description><link>https://elinep.github.io/blog/2017/06/12/neural_networks_training_basics.html</link><guid isPermaLink="true">https://elinep.github.io/blog/2017/06/12/neural_networks_training_basics.html</guid><category><![CDATA[HubPress]]></category><category><![CDATA[Blog]]></category><category><![CDATA[Open_Source]]></category><pubDate>Mon, 12 Jun 2017 00:00:00 GMT</pubDate></item></channel></rss>