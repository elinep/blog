<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Untitled RSS Feed]]></title><description><![CDATA[Untitled RSS Feed]]></description><link>https://elinep.github.io/blog</link><generator>RSS for Node</generator><lastBuildDate>Tue, 13 Jun 2017 10:02:02 GMT</lastBuildDate><atom:link href="https://elinep.github.io/blog/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Neural Networks Training: basic concepts]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>I recently starter to be interested in neural networks attracted by all the
magical articles/results that flood the web.
When you see magic, you want to understand the trick. That’s my case.
A great resource to study this subject is the
<a href="https://www.youtube.com/watch?v=yp9rwI_LZX8&amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg">Convolutional Neural Networks</a> course by Standford.
This series of videos is nice and show that neural network concepts are accessible.
There is still few points that struggled me for a while and my modest intent is
that this post freshly written after having watched the video could help for a
better understanding.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_what_is_a_neural_network">What is a neural network ?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>OK first, what kind of beast a neural network is and what’s its purpose. Well
it’s just a giant function that process some input based on some parameters to
compute some output.</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="https://elinep.github.io/blog/images/2017-06-12-neural_networks_training_basics/fig1.png" alt="fig1.png">
</div>
<div class="title">Figure 1. Abstract view of a neural network</div>
</div>
<div class="paragraph">
<p>So basically you present to your network some input data (images, numbers, text)
and it generates an output (images, numbers, text) by computing:</p>
</div>
<div class="paragraph text-center">
<p>\(Y = f(X,W)\)</p>
</div>
<div class="paragraph">
<p>Note that the dimensions of \(X\),\(Y\) and \(W\) are generally different.
For example for an image classification task:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>\(X\) will be the dimensions of the image (example 128x128)</p>
</li>
<li>
<p>\(Y\) will be the number of class (example 10) you want to detect</p>
</li>
<li>
<p>\(W\) can be very large like millions of coefficients</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The \(f()\) function is a kind of generic one defined by your network
architecture and depends on:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>type of neuron</p>
</li>
<li>
<p>number of neurons</p>
</li>
<li>
<p>how neurons interconnect each other</p>
</li>
<li>
<p>&#8230;&#8203;</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Its behavior is driven by the weights. The weights are the parameters you have to
tune so that \(f()\) does something interesting i.e. produces relevant output
given the input and not just garbage.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_what_is_training">What is training ?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The goal of training is to find the value of the weights so that the network
generates correct output.</p>
</div>
<div class="paragraph">
<p>On supervised learning you present examples of input data and expected output.
At the beginning the network will generate outputs far different from the
expected ones.</p>
</div>
<div class="paragraph">
<p>The difference between output and expected output is used to update the weights
so that the error decreased.</p>
</div>
<div class="paragraph">
<p>After many example submission and weights optimization cycle, you hope your
network works correctly and can predict correctly new output with unseen data.</p>
</div>
<div class="paragraph">
<p>So basically network training is a function fitting task.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_how_do_you_train">How do you train ?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>OK first we need to measure the error between an expected output and current
output of the network.</p>
</div>
<div class="paragraph">
<p>This is called a loss function and it is added at the end of the network like this:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="https://elinep.github.io/blog/images/2017-06-12-neural_networks_training_basics/fig2.png" alt="fig2.png">
</div>
<div class="title">Figure 2. Loss function to compute error</div>
</div>
<div class="paragraph">
<p>The loss function should have several properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>its input are the output of the network and the output from the training data</p>
</li>
<li>
<p>its output is a scalar</p>
</li>
<li>
<p>it should measure properly the error : the more \(Y\) and \(\tilde{Y}\)
are close, the less the error must be</p>
</li>
<li>
<p>it must be differentiable</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>There are several ad-hoc loss function that we can use depending on our application.
A very simple one - the \(L2\) norm - consists in summing the square error on
each output dimensions:</p>
</div>
<div class="paragraph text-center">
<p>\(L(Y,\tilde{Y}) = \sum{(Y_i-\tilde{Y_i})^2}\)</p>
</div>
<div class="paragraph">
<p>The training consists of finding the weights of the network that minimize the
error. In math language, we perform:</p>
</div>
<div class="paragraph text-center">
<p>\(\underset{W}{\arg\min{}} L(Y,\tilde{Y})\)</p>
</div>
<div class="paragraph">
<p>It’s not a straight forward job. The problem is that the loss function is on top
of the network which is a giant non linear function. We can’t compute the minimum
right away from the data, network and loss function.</p>
</div>
<div class="paragraph">
<p>How do we do then ? The answer is <strong>gradient descent</strong>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_gradient_descent">Gradient descent</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Gradient descent is widely use to optimize function parameter. The basic idea is
to test how the error evolves when slightly modifying each parameter.</p>
</div>
<div class="sect2">
<h3 id="_analogy">Analogy</h3>
<div class="paragraph">
<p>The famous analogy is a blind folded walker in the mountain looking for the valley.</p>
</div>
<div class="paragraph">
<p>One possible strategy is to sense the slope by making tiny steps:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>make a tiny step forward (X-axis) and sense if you’re going uphill or downhill
(i.e. watch how you move on Z-axis). Go back to your position</p>
</li>
<li>
<p>make a tiny side step (Y-axis) and sense if you’re going uphill or downhill
(i.e. watch how you move on Z-axis). Go back to your position</p>
</li>
<li>
<p>Thanks to this two steps, you know how the slope is oriented and you can make
a step in the correct direction, generally a mixed of X and Y</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>After several iterations you likely end in the valley, or at least in a local
valley.</p>
</div>
<div class="paragraph">
<p>The analogy points are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>the altitude (along Z-axis) is the error</p>
</li>
<li>
<p>your position (along X-axis and Y-axis) are the 2 parameters you want to
optimize to find the minimum error</p>
</li>
<li>
<p>the tiny steps to sense the slope is the gradient</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_simple_example">Simple example</h3>
<div class="paragraph">
<p>Let’s formalize a bit this strategy with an example.
Imagine you have the following loss function:</p>
</div>
<div class="paragraph text-center">
<p>\(L(w_1,w_2) = (w_1+2)^2+4(w_2-1)^2+3\)</p>
</div>
<div class="paragraph">
<p>To perform gradient descent, we need to compute the gradient of this loss function.
The gradient is just the set of partial derivative of the loss function for the
weight parameters.</p>
</div>
<div class="paragraph text-center">
<p>\(
\nabla L(w_1,w_2) =
\begin{bmatrix}
\frac{\partial L(w_1,w_2)}{\partial w_1}
\\
\frac{\partial L(w_1,w_2)}{\partial w_2}
\end{bmatrix}\)</p>
</div>
<div class="paragraph">
<p>The partial derivatives allows us to evaluate the slope along each axis at any
given position. Our simple loss function is easy to derivate:</p>
</div>
<div class="paragraph text-center">
<p>\(
\nabla L(w_1,w_2) =
\begin{bmatrix}
\frac{\partial L(w_1,w_2)}{\partial w_1}
\\
\frac{\partial L(w_1,w_2)}{\partial w_2}
\end{bmatrix}
=
\begin{bmatrix}
2w_1+4
\\
8w_2-8
\end{bmatrix}\)</p>
</div>
<div class="paragraph">
<p>Now that we can compute the slope we can run the algorithm:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>evaluate the local gradient at the current position</p>
</li>
<li>
<p>update the position by making step proportional to the local gradient</p>
</li>
<li>
<p>go back to 1.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Let’s do the first iteration:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>we start at a random position \(w_1=-5, w_2=5\)</p>
</li>
<li>
<p>we evaluate the gradient at this position
\(
\nabla L(-5,5) =
\begin{bmatrix}
\frac{\partial L(-5,5)}{\partial -5}
\\
\frac{\partial L(-5,5)}{\partial 5}
\end{bmatrix}
=
\begin{bmatrix}
2\times-5+4
\\
8\times5-8
\end{bmatrix}
=
\begin{bmatrix}
-6
\\
32
\end{bmatrix}\)
which means that locally the error decreases a bit when \(w_1\) increases,
and the error increases a lot when \(w_2\) increases.
Therefore to go downhill we have to increase \(w_1\) and decrease \(w_2\)</p>
</li>
<li>
<p>Update current position to go downhill
\(
\begin{bmatrix}
w_1
\\
w_2
\end{bmatrix}
=
\begin{bmatrix}
w_1
\\
w_2
\end{bmatrix}
-
\lambda
\nabla L(w_1,w_2)
=
\begin{bmatrix}
-5+6\lambda
\\
5-32\lambda
\end{bmatrix}\)
where \(\lambda\) is a scalar parameter to control the size of your step</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Here is graphically what happens for few iterations with \(\lambda=0.04\):</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="https://elinep.github.io/blog/images/2017-06-12-neural_networks_training_basics/fig_gradient_descent.png" alt="fig gradient descent.png">
</div>
<div class="title">Figure 3. Gradient descent iterations for a simple function - The red dot, is the initial position. The arrows represents the evaluation of the current gradient (the slope on each axis). The surface is the loss function.</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
When to stop the algorithm? Generally for neural networks training,
you run it a fix number of times. It is one of your hyperparameter. In the same
time you monitor that your error behave correctly (i.e. decreases)
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>We presented the basic gradient descent algorithm. It has a disadvantage of being
very slow (you need a lot of iteration to find the best position). There are
clever way to update the position but they all rely on the local gradient
evaluation.</p>
</div>
<div class="paragraph">
<p>OK so to train a neural network, we need to compute the partial derivative of
the loss:</p>
</div>
<div class="paragraph text-center">
<p>\(\frac{\partial L(f(X,W),\tilde{Y})}{\partial{W_i}}\)</p>
</div>
<div class="paragraph">
<p>The problem is that it’s not straightforward as \(f()\) can be very complex.
We can’t compute it by hand as we did with our little example. We could evaluate
numerically the gradient by running the network with tiny variation on each weight
at a time and monitor the error but it has drawbacks:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>it is an approximation</p>
</li>
<li>
<p>you need to run the network (i.e. evaluate ) as many times as the number of
weights just for one gradient descent iteration which is impractical.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The solution is the <strong>backward propagation</strong>.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_backward_propagation">Backward propagation</h2>
<div class="sectionbody">
<div class="paragraph">
<p>So far we abstracted the neural network with the function \(Y = f(X,W)\).
Before introducing back propagation, let’s see how this function looks like.</p>
</div>
<div class="sect2">
<h3 id="_neural_networks_under_the_hood">Neural networks, under the hood</h3>
<div class="paragraph">
<p>A neural network is a composition of elementary functions called neurons.
The neuron transformation is quite basic. It combines the input and generate a
scalar output. There are several variants but here is a typical one:</p>
</div>
<div class="paragraph text-center">
<p>\(Y = f_{neuron}(X,W,B) = \max(0,\sum\limits_{i=0}^{N}{(X_i \cdot W_i)}+B)\)</p>
</div>
<div class="paragraph text-center">
<p>with \(Y \in \mathbb{R}\), \(X \in \mathbb{R}^N\), \(W \in \mathbb{R}^{N}\)
and \(B \in \mathbb{R}\)</p>
</div>
<div class="paragraph">
<p>This function simply computes a weighted sum of the input data,
adds a bias and saturates the result with \(\max()\). The \(\max()\) part
is called the activation function.
There are different possible activation functions.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The bias like the weights is a parameter that needs to be trained.
That’s why \(B\) is often omitted and included in \(W\) and we simply write: \(Y = f_{neuron}(X,W)\)
with \(W \in \mathbb{R}^{N+1}\)
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>By chaining several layers of neurons, you obtain a neural network:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="https://elinep.github.io/blog/images/2017-06-12-neural_networks_training_basics/fig3.png" alt="fig3.png">
</div>
<div class="title">Figure 4. A neural network</div>
</div>
<div class="paragraph">
<p>Backward propagation is a recursive method to evaluate the gradient of
the loss function (i.e. \(\frac{\partial L(Y,\tilde{Y})}{\partial W_i}\))
by considering one simple neuron at a time.</p>
</div>
</div>
<div class="sect2">
<h3 id="_chain_rule">Chain rule</h3>
<div class="paragraph">
<p>Backward propagation relies on the chain rule.
The chain rule is a method to compute the derivative of the composition of
two functions.</p>
</div>
<div class="paragraph">
<p>Consider two functions \(y_f=f(x_f)\), \(y_g=g(x_g)\) and compose them
to form a third one:</p>
</div>
<div class="paragraph text-center">
<p>\(y=h(x)=g(f(x))\)</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="https://elinep.github.io/blog/images/2017-06-12-neural_networks_training_basics/fig4.png" alt="fig4.png">
</div>
<div class="title">Figure 5. Composition of two functions</div>
</div>
<div class="paragraph">
<p>Chain rule states:</p>
</div>
<div class="paragraph text-center">
<p>\(\frac{df}{dx}(a) = \frac{dg}{df}(f(a)) \cdot \frac{df}{dx}(a)\)</p>
</div>
<div class="paragraph">
<p>In other word, to derivate a composition of function we simply multiply the
derivative of the underlying functions where they are individually evaluated.</p>
</div>
<div class="paragraph">
<p>Let’s see with an example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>\(f(x)=3x+1\)</p>
</li>
<li>
<p>\(g(f)=f^2\)</p>
</li>
<li>
<p>\(h(x)=g(f(x))=(3x+1)^2=9x^2+6x+1\)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>By evaluating the derivative of \(h\) on point \(a\) directly we find:</p>
</div>
<div class="paragraph text-center">
<p>\(\frac{dh}{dx}(a) = 18a+6\)</p>
</div>
<div class="paragraph">
<p>With the chain rule method we find:</p>
</div>
<div class="paragraph text-center">
<p>\(\frac{dg}{df}=2f\), \(\frac{df}{dx}=3\)</p>
</div>
<div class="paragraph">
<p>so,</p>
</div>
<div class="paragraph text-center">
<p>\(\frac{dg}{df}(f(a))=2f(a)=2(3a+1)\), \(\frac{df}{dx}(a)=3\)</p>
</div>
<div class="paragraph">
<p>putting all together,</p>
</div>
<div class="paragraph text-center">
<p>\(\frac{dh}{dx}(a)=\frac{dg}{df}(f(a)) \cdot \frac{df}{dx}(a) = (6a+2) \cdot 3 = 18a+6\)
as expected</p>
</div>
<div class="paragraph">
<p>From \(f\) point of view, it means that to compute the derivative regarding \(x\)
for a particular value \(a\), we need:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>\(\frac{df}{dx}(a)\), the local derivative</p>
</li>
<li>
<p>\(\frac{dg}{df}(f(a))\) which is the evaluation of the local derivative of
the next « block » i.e. the \(g\) function</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_chain_rule_applied_to_a_network">Chain rule applied to a network</h3>
<div class="paragraph">
<p>The idea of back propagation is to apply chain rule on the loss function
\(L(Y,\tilde{Y})\).
For each function of the network (neuron, loss) we will evaluate the gradient of
the output regarding the input that are influenced by the weights of the networks.</p>
</div>
<div class="sect3">
<h4 id="_gradient_propagation_in_the_loss_function">Gradient propagation in the loss function</h4>
<div class="paragraph">
<p>We start by evaluating the gradient of the error on the loss function.
The loss function depends on two variable:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>the network output \(Y\) which obviously depends on the weights \(W\).
The gradient \(G_Y\) must be evaluated</p>
</li>
<li>
<p>the expected output \(\tilde{Y}\) from the training data which does not depend
on the weight. There is no need to compute \(G_{\tilde{Y}}\)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For the loss function we introduced earlier we have:</p>
</div>
<div class="paragraph text-center">
<p>\(G_{Y_i} = \frac{\partial L(Y,\tilde{Y})}{\partial Y_i}
= \frac{\partial \sum{(Y_i-\tilde{Y_i})^2} }{\partial Y_i}
= 2(Y_i - \tilde{Y}_i)\)</p>
</div>
<div class="paragraph">
<p>Once the gradient has been evaluated in the loss function, it can flows in the
neurons. We transmit \(G_Y\) to the last neurons of the network which are placed
right before the loss function.
These last neuron will also compute gradient and transmit it to their ancestors
and so on until we reach the first neurons of the network.</p>
</div>
</div>
<div class="sect3">
<h4 id="_gradient_propagation_in_a_neuron">Gradient propagation in a neuron</h4>
<div class="paragraph">
<p>Let&#8217;s focus on one neuron and assume we receive the gradient \(G_Y\) from the
next neurons (i.e. all the neurons that use our output as input) or from the loss
function when we are one of the last neurons.</p>
</div>
<div class="paragraph">
<p>Thanks to the chain rule we compute the following gradients:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>the weight gradient \(G_{W_i} = G_Y \cdot \frac{\partial F_{neuron}(X,W)}{\partial W_i}\)
senses the influence of the neuron&#8217;s weights on the final error. \(G_{W_i}\)
will be used to update the current neuron weights</p>
</li>
<li>
<p>the weight gradient \(G_{B} = G_Y \cdot \frac{\partial F_{neuron}(X,W)}{\partial B}\)
for the same reason. \(G_{B}\) will be used to update the current neuron bias</p>
</li>
<li>
<p>the input gradient \(G_{X_i} = G_Y \cdot \frac{\partial F_{neuron}(X,W)}{\partial X_i}\)
senses the influence of the current neuron input on the final error. \(G_{X_i}\)
will tell to the previous neuron how it should modify its output so that our
output help to decrease the error.</p>
</li>
</ul>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="https://elinep.github.io/blog/images/2017-06-12-neural_networks_training_basics/fig5.png" alt="fig5.png">
</div>
<div class="title">Figure 6. Gradient flow inside a neuron</div>
</div>
<div class="paragraph">
<p>With the neuron definition we have seen, we obtain:</p>
</div>
<div class="paragraph text-center">
<p>\({F_{neuron}(X,W,B) = \max(0,\sum\limits_{i=0}^{N}{(X_i \cdot W_i)}+B)} = Y\)</p>
</div>
<div class="paragraph text-center">
<p>\(G_{W_i} = G_Y \cdot \frac{\partial F_{neuron}(X,W,B)}{\partial W_i}
=G_Y \cdot
\Big\{
\begin{matrix}
X_i &amp; Y&gt;0 \\
0 &amp; Y \leqslant 0
\end{matrix}\)</p>
</div>
<div class="paragraph text-center">
<p>\(G_{B} = G_Y \cdot \frac{\partial F_{neuron}(X,W,B)}{\partial W_B}
=G_Y \cdot
\Big\{
\begin{matrix}
1 &amp; Y&gt;0 \\
0 &amp; Y \leqslant 0
\end{matrix}\)</p>
</div>
<div class="paragraph text-center">
<p>\(G_{X_i} = G_Y \cdot \frac{\partial F_{neuron}(X,W,B)}{\partial W_i}
=G_Y \cdot
\Big\{
\begin{matrix}
W_i &amp; Y&gt;0 \\
0 &amp; Y \leqslant 0
\end{matrix}\)</p>
</div>
<div class="paragraph">
<p>\(G_{X_i}\) are transmitted to previous neurons while \(G_{W_i}\) and
\(G_{B}\) are used by the gradient descent algorithm to update parameters
\(W\) and \(B\) for the current neuron.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Most of the time a neuron output is linked to multiple neurons.
Therefore during back propagation a neuron receive several \(G_{Y_i}\) gradients.
The gradient used for back propagation is simply the sum of all the incoming
gradients \(G_Y = \sum{G_{Y_i}}\) (see <a href="https://en.wikipedia.org/wiki/Chain_rule#Higher_dimensions" class="bare">https://en.wikipedia.org/wiki/Chain_rule#Higher_dimensions</a>).
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_training_process_overview">Training process overview</h2>
<div class="sectionbody">
<div class="paragraph">
<p>We have all the tools required to train a network. Let&#8217;s summarize:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>we set up a network by connecting multiple neurons</p>
</li>
<li>
<p>we prepare training data: input \(X\) and ground truth associated output
\(Y\)</p>
</li>
<li>
<p>we choose a loss function and add it at the end of the network</p>
</li>
<li>
<p>we pick up an example and run it through the network and the loss function
(<strong>forward propagation</strong>)</p>
</li>
<li>
<p>we compute gradient from the loss function to the first neurons of the network
(<strong>backward propagation</strong>)</p>
</li>
<li>
<p>thanks to the weight and bias gradients, we make a tiny update of the neuron&#8217;s
weights and bias (<strong>gradient descent</strong>)</p>
</li>
<li>
<p>we go back to <strong>4</strong> and loop for many iterations.</p>
</li>
</ol>
</div>
</div>
</div>]]></description><link>https://elinep.github.io/blog/2017/06/12/neural_networks_training_basics.html</link><guid isPermaLink="true">https://elinep.github.io/blog/2017/06/12/neural_networks_training_basics.html</guid><category><![CDATA[Blog]]></category><category><![CDATA[Neural network]]></category><pubDate>Mon, 12 Jun 2017 00:00:00 GMT</pubDate></item></channel></rss>